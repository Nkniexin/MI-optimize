  quant_config:
    algo: rtn
    kwargs:
      w_dtype: int8    # select from ['int2', 'int3', 'int4', 'int8', 'float16']
      a_dtype: int8   # select from ['int2', 'int3', 'int4', 'int8', 'float16']
      calibrate_seq_length: 2048
      device: 'cuda'
      offload: 'cpu'
      w_groupsize: -1
      a_groupsize: -1
      a_qtype: "per_tensor"              
      w_qtype: "per_channel"             
      w_has_zero: False
      a_has_zero: False
      w_unsign: True
      a_unsign: True
      quantization_type: 'static'
      block_sequential: True
      layer_sequential: True
      skip_layers:                   # the linear layer to skip, should match the module name
        - lm_head
    calibrate_config:
      name: 'cmmlu'
      split: val
      calibrate_subject: Humanities
      calibrate_nums:
        arts: 12
        college_law: 11
        global_facts: 11
        international_law: 11
        jurisprudence: 12
        logical: 11
        marxist_theory: 12
        philosophy: 12
        professional_law: 12
        world_history: 12
        world_religions: 12
      calibrate_seqlen: 2048
      shuffle: False
  